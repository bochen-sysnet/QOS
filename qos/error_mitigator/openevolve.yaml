max_iterations: 500
checkpoint_interval: 10
log_level: "INFO"
log_dir: null
random_seed: 42

# Rewrite mode: output full file each iteration (stable with OE markers)
diff_based_evolution: false
max_code_length: 30000

early_stopping_patience: null
convergence_threshold: 0.001
early_stopping_metric: "combined_score"

llm:
  api_base: "http://localhost:8000/v1"
  primary_model: "Qwen/Qwen2.5-Coder-14B-Instruct-AWQ"
  temperature: 0.75
  top_p: 0.92
  max_tokens: 1800
  timeout: 450
  retries: 3
  retry_delay: 1

prompt:
  system_message: |
    You are OpenEvolve. You are optimizing ONLY the function evolved_run(self, q).

    CRITICAL OUTPUT REQUIREMENT:
      - Always output the ENTIRE FILE (all imports + full evolved_run definition), not just the OE region.
      - HOWEVER, you MUST ONLY MODIFY code between markers '# OE_BEGIN' and '# OE_END'.
      - Do not change imports, module-level code, class/function signatures, or anything outside markers.

    TASK CONTEXT:
      - Input q is a Qernel. Metadata is available via q.get_metadata().
      - evolved_run is stateless across calls (no caching across runs).
      - Evaluator selects circuits uniformly at random (uniform selection).
      - evolved_run is the LAST transformation in the pipeline.

    Your job is to make evolved_run decide the error-mitigation pipeline (freezing / cutting / reuse / GV) depending on these features.

    AVAILABLE TECHNIQUES (already implemented elsewhere):
      - Frozen qubit (FrozenQubitsPass)
      - Gate virtualisation (applyGV)
      - Wire cutting (applyWC)
      - Qubit reuse (applyQR)

    METRICS:
      - rel_depth: depth(QOSE) / depth(QOS)
      - rel_cnot:  cnot(QOSE) / cnot(QOS)
      - rel_overhead: num_circuits(QOSE) / num_circuits(QOS)
      - combined_score (maximize):
          combined_score = 1.0 / (1.0 + rel_depth + rel_cnot + rel_overhead/10.0)

    IMPORTANT:
      - budget is the constraint for baseline QOS and is NOT necessarily a hard constraint for evolved_run.
        You may treat it only as a soft heuristic.

    ARTIFACTS PROVIDED BY EVALUATOR (per case):
      - input_features: depth, num_qubits, num_nonlocal_gates, program_communication, liveness,
        parallelism, measurement, entanglement_ratio, critical_depth
      - stage_counts: call counts for computeCuttingCosts, applyGV, applyWC, applyQR, FrozenQubitsPass
      - stage_order: sequence of these calls
      Use artifacts to diagnose regressions and avoid repeated computeCuttingCosts loops.

    HARD CONSTRAINTS:
      - Deterministic execution (no randomness).
      - Runtime: bounded candidate search; do NOT use unbounded loops.
      - Do not introduce new imports or new module dependencies.

    IMPORTANT LEVERS TO EXPLORE (must explore across evolution):
      A) Pipeline decision based on metadata:
         - Decide whether to apply FQ, WC, GV, QR, and in what order, based on input_meta.
         - Use safe defaults if a key is missing (input_meta.get(key) is None).

      B) Improve size_to_reach design:
         - "size_to_reach > 2" is a heuristic; you may replace with a metadata-driven rule,
           e.g. min_size threshold depending on num_qubits / connected components / nonlocal gates.
         - You may explore different stopping rules and candidate sets of sizes.

      C) Improve the search for size_to_reach:
         - Current approach uses two while loops / iterative shrinking.
         - Improve it using:
             - caching computeCuttingCosts(q, size) within a call
             - bracket + binary search (if you assume monotonicity)
             - small candidate-set evaluation around an initial guess and choose best feasible
         - DO NOT change the meaning of QOS_COST_SEARCH_MAX_ITERS: it must remain an upper bound on iterations.

      D) Improve freezing heuristic (QAOA hotspots logic):
         - Replace the brittle rule:
             for i in range(2):
                 if hotspots[i] / num_cnots >= 0.07: ...
           with a metadata-driven, robust rule:
             - handle num_cnots==0 or missing hotspots
             - allow top-k, percentile, dynamic threshold, or using entanglement_ratio/critical_depth
             - cap qubits_to_freeze reasonably (e.g. <= num_qubits-1)
         - Keep deterministic behavior.

      E) Global thinking:
         - Consider interactions: e.g., FQ may reduce nonlocal gates and change cutting costs;
           QR may reduce effective width, which changes feasible cutting size.
         - Favor strategies that choose pipeline based on predicted downstream benefit.


  evaluator_system_message: "You are a strict code reviewer. Do not add commentary."
  num_top_programs: 2
  num_diverse_programs: 2
  use_template_stochasticity: true

  # Make sure OpenEvolve passes artifacts back into the model prompt each iteration.
  include_artifacts: true
  max_artifact_bytes: 65536
  artifact_security_filter: true

database:
  db_path: openevolve_output/db
  in_memory: false
  log_prompts: true

  population_size: 24
  archive_size: 16
  num_islands: 4

  migration_interval: 30
  migration_rate: 0.12

  elite_selection_ratio: 0.05
  exploration_ratio: 0.65
  exploitation_ratio: 0.30

  feature_dimensions:
    - "complexity"
    - "diversity"
  feature_bins: 12
  diversity_reference_size: 30

evaluator:
  timeout: 300
  max_retries: 1
  cascade_evaluation: false
  parallel_evaluations: 1
  use_llm_feedback: false
  llm_feedback_weight: 0.0

evolution_trace:
  enabled: false
  format: "jsonl"
  include_code: false
  include_prompts: false
  output_path: openevolve_output/evolution_trace.jsonl
  buffer_size: 10
  compress: false
