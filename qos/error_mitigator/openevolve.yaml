max_iterations: 500
checkpoint_interval: 10
log_level: "INFO"
log_dir: null
random_seed: 42

# Rewrite mode: output full file each iteration (stable with OE markers)
diff_based_evolution: false
max_code_length: 30000

early_stopping_patience: null
convergence_threshold: 0.001
early_stopping_metric: "combined_score"

llm:
  api_base: "http://localhost:8000/v1"
  primary_model: "Qwen/Qwen2.5-Coder-14B-Instruct-AWQ"
  temperature: 0.8
  top_p: 0.92
  max_tokens: 1400
  timeout: 450
  retries: 3
  retry_delay: 1

prompt:
  system_message: |
    Optimize ONLY evolved_run(self, q) in qos/error_mitigator/evolution_target.py between # OE_BEGIN and # OE_END.

    Qernel metadata:
    input_meta = q.get_metadata() (keys may be missing; use .get()).
    Keys may include:
      Simple: depth, num_qubits, num_nonlocal_gates, num_connected_components, num_cnot_gates, num_measurements
      Supermarq: program_communication, liveness, parallelism, measurement, entanglement_ratio, critical_depth
    Use metadata to decide whether/when to apply: FrozenQubitsPass (FQ), applyGV (GV), applyWC (WC), applyQR (QR).

    EVALUATION (maximize combined_score):
      rel_depth = QOSE_depth / QOS_depth (smaller better)
      rel_cnot  = QOSE_cnot  / QOS_cnot  (smaller better)
      rel_overhead = QOSE_num_fragments / QOS_num_fragments (smaller better)
      combined_score = 1 / (1 + rel_depth + rel_cnot + rel_overhead/100)
    IMPORTANT: rel_depth and rel_cnot dominate; rel_overhead is 100× weaker. Do NOT trade big depth/CNOT increases for small fragment reductions.
    Evaluator randomly samples 3 circuits and averages metrics → prioritize robust average-case, avoid regressions on easy circuits.

    High-impact edits to explore (keep changes conservative; 1–2 logic changes per candidate):
      - Add metadata-driven SKIP logic (do nothing on small/low-nonlocal circuits).
      - Improve QAOA freezing heuristic (top-k/threshold) safely: handle num_nonlocal_gates==0, <k hotspots, missing keys.
      - Improve size_to_reach/min_size rule ("size_to_reach > 2" is a heuristic).
      - Improve size search while keeping QOS_COST_SEARCH_MAX_ITERS meaning unchanged; cache computeCuttingCosts(q, size) within evolved_run.

    Hard constraints:
      - Output COMPLETE updated program code only (no markdown/diff/commentary).
      - Everything outside OE_BEGIN/OE_END must be byte-identical; keep markers unchanged.
      - Do not change imports or any function signatures.
      - Deterministic only; keep runtime short.

  evaluator_system_message: "You are a strict code reviewer. Do not add commentary."
  num_top_programs: 2
  num_diverse_programs: 2
  use_template_stochasticity: true
  include_artifacts: false
  max_artifact_bytes: 20480
  artifact_security_filter: true
  template_variations:
    strategy:
      - "Focus on metadata-driven pipeline selection and skip logic for FQ/WC/GV/QR."
      - "Focus on improving size_to_reach search: caching + bracketed or candidate-set search; keep max_iters semantics."
      - "Focus on redesigning freezing heuristic using robust top-k/percentile logic and metadata (entanglement_ratio, critical_depth)."
      - "Focus on global optimization: choose pipeline order and parameters to minimize downstream costs, not local heuristics."

database:
  db_path: openevolve_output/db
  in_memory: false
  log_prompts: true

  # Novelty-oriented island model
  population_size: 24
  archive_size: 16
  num_islands: 4

  migration_interval: 30
  migration_rate: 0.12

  elite_selection_ratio: 0.05
  exploration_ratio: 0.65
  exploitation_ratio: 0.30

  feature_dimensions:
    - "complexity"
    - "diversity"
  feature_bins: 12
  diversity_reference_size: 30

evaluator:
  timeout: 300
  max_retries: 1
  cascade_evaluation: false
  parallel_evaluations: 1
  use_llm_feedback: false
  llm_feedback_weight: 0.0

evolution_trace:
  enabled: false
  format: "jsonl"
  include_code: false
  include_prompts: false
  output_path: openevolve_output/evolution_trace.jsonl
  buffer_size: 10
  compress: false
