max_iterations: 100
checkpoint_interval: 10
log_level: "INFO"
log_dir: null
random_seed: 42
max_tasks_per_child: 1

# Rewrite mode: output full file each iteration (stable with OE markers)
diff_based_evolution: false
max_code_length: 30000

early_stopping_patience: null
convergence_threshold: 0.001
early_stopping_metric: "combined_score"

llm:
  api_base: "${OPENAI_API_BASE}"
  api_key: "${OPENAI_API_KEY}"
  # available gpt models: gpt-5.2, gpt-5.1, gpt-5, gpt-5-nano
  # available gemini models: gemini-2.5-flash-lite
  # available qwen models: Qwen/Qwen2.5-Coder-14B-Instruct-AWQ
  primary_model: "${OPENAI_MODEL}"
  temperature: 0.7
  top_p: 0.9
  max_tokens: 4096
  timeout: 450
  retries: 3
  retry_delay: 5

prompt:
  system_message: |
    You are optimizing ONLY the function evolved_cost_search(self, q, size_to_reach, budget)
    in qos/error_mitigator/evolution_target.py.

    OUTPUT FORMAT (CRITICAL):
    - Return the full file contents of qos/error_mitigator/evolution_target.py.
    - Output code only: no explanations, no markdown fences, no extra text.

    GENERALIZATION REQUIREMENT (CRITICAL):
    - The evaluator samples random (circuit_type, num_qubits) pairs each run.
    - Qubit counts are constrained to [12,24] and must exist in the benchmark set.
    - Your logic must generalize across circuit families (QAOA, BV, GHZ, VQE, QSVm, etc.) and sizes.
    - Do NOT branch on q.get_name(), bench strings, or any per-benchmark constants.

    FUNCTION CONTRACT (MUST FOLLOW EXACTLY):
    - Do NOT change the function signature.
      It MUST remain: evolved_cost_search(self, q, size_to_reach, budget)
    - It MUST return EXACTLY 2 values: (size_to_reach: int, method: str) where method is "GV" or "WC".
    - If you violate signature/return arity, evaluation will fail.

    CONTEXT:
    The input q is a Qernel. It contains metadata computed elsewhere, accessible via:
      input_meta = q.get_metadata()

    Useful fields may include:
      depth, num_qubits, num_clbits, num_nonlocal_gates, num_connected_components,
      number_instructions, num_measurements, num_cnot_gates,
      program_communication, liveness, parallelism, measurement,
      entanglement_ratio, critical_depth.

    Inputs/Outputs:
      - Inputs:
          * q: the Qernel (quantum circuit container) whose metadata informs the decision.
          * size_to_reach: the current target circuit size for cutting/virtualization search.
          * budget: the cost threshold used to decide whether GV/WC is acceptable.
      - Outputs:
          * size_to_reach: the chosen target size to use for the cutting/virtualization of the target circuit.
          * method: "GV" or "WC", which determines which technique is applied at that size.
      - Cost logging and traces are handled outside this file (in qos/error_mitigator/run.py).

    IMPORTANT PRACTICAL CONSTRAINTS:
    - `budget` is only meaningful for your cost-search logic (i.e., your own GV/WC cost queries).
      Do not assume downstream will enforce budget.
    - If size_to_reach >= num_qubits, the decomposition can become a no-op.
      Use that ONLY as an explicit fallback when costs indicate everything else is too expensive.
      Prefer to clamp sizes into a meaningful range (e.g., [2, num_qubits-1]) for real action.

    EFFICIENCY / GENERALIZATION GUIDELINES (HIGH IMPACT):
    - Minimize gv/wc cost calls. Avoid long +/-1 stepping loops.
      Prefer a small number of probes + bounded search (e.g., check a few candidate sizes,
      or use a short binary/ternary-style search on a clamped interval).
    - Use cheap metadata heuristics first; only call compute_*_cost when needed.
    - Keep behavior monotone and stable: similar circuits should yield similar decisions.

    NOTE: "QOS" refers to the baseline implementation, and "QOSE" refers to the evolved program.

    METRICS:
      - qose_depth: average depth ratio (QOSE/QOS)
      - qose_cnot: average nonlocal gate ratio (QOSE/QOS)
      - qose_overhead: average circuit-count ratio (QOSE/QOS)
      - avg_run_time: average runtime ratio (QOSE/QOS)
      - combined_score (maximize): scoring policy is configured externally and
        recorded in evaluator artifacts (`score_formula`).
    NOTE:
      - Depth/CNOT ratios are proxies for fidelity. The goal is to improve fidelity,
        reduce cost-search time, and avoid depth/CNOT regressions.

    We provide the execution outputs of the last program executed by the evaluator. 
    Use them to diagnose decisions. Details of the execution outputs are as follows:

    EXECUTION OUTPUTS PROVIDED BY EVALUATOR (summary):
      - qose_budget: budget used for all cases
      - qose_run_sec_avg: average runtime of evolved mitigator
      - qos_run_sec_avg: average runtime of baseline QOS
      - gv_cost_calls_total: total GV cost calls (evolved)
      - wc_cost_calls_total: total WC cost calls (evolved)
      - qos_gv_cost_calls_total: total GV cost calls (baseline)
      - qos_wc_cost_calls_total: total WC cost calls (baseline)
      - qos_depth_avg: average absolute depth of baseline circuits
      - qos_cnot_avg: average absolute nonlocal gate count of baseline circuits

    EXECUTION OUTPUTS PROVIDED BY EVALUATOR (per case):
      - input_features: static circuit features (depth, qubits, gates, etc.)
        num_connected_components, number_instructions, num_measurements, num_cnot_gates,
        program_communication, liveness, parallelism, measurement, entanglement_ratio, critical_depth
      - qose_input_size: initial target size before cost-search adjustments
      - qose_depth, qos_depth, qose_cnot, qos_cnot,
        qose_run_sec, qos_run_sec: paired QOSE vs baseline QOS metrics
      - qose_output_size: final target size chosen by the algorithm
      - qose_method: chosen method ("GV" or "WC")
      - qose_gv_cost_trace, qose_wc_cost_trace: cost estimates per probe step
      - qose_gv_time_trace, qose_wc_time_trace: time per probe step

    AN EXAMPLE OF EVOLVEMENT without cost search (Not Optimal):
    def evolved_cost_search(self, q: Qernel, size_to_reach: int, budget: int):
      metadata = q.get_metadata()
      depth = metadata.get("depth", 0)
      num_qubits = metadata.get("num_qubits", 0)
      num_clbits = metadata.get("num_clbits", 0)
      num_nonlocal_gates = metadata.get("num_nonlocal_gates", 0)
      num_connected_components = metadata.get("num_connected_components", 0)
      number_instructions = metadata.get("number_instructions", 0)
      num_measurements = metadata.get("num_measurements", 0)
      num_cnot_gates = metadata.get("num_cnot_gates", 0)
      program_communication = metadata.get("program_communication", 0.0)
      liveness = metadata.get("liveness", 0.0)
      parallelism = metadata.get("parallelism", 0.0)
      measurement = metadata.get("measurement", 0.0)
      entanglement_ratio = metadata.get("entanglement_ratio", 0.0)
      critical_depth = metadata.get("critical_depth", 0.0)

      input_size = size_to_reach

      # OE_BEGIN
      def _as_int(x, default=0):
          try:
              return int(x)
          except Exception:
              return default

      def _as_float(x, default=0.0):
          try:
              return float(x)
          except Exception:
              return default

      b = max(0, _as_int(budget, 0))
      in_size = max(2, _as_int(size_to_reach, 2))
      n = _as_int(num_qubits, 0)

      er = _as_float(entanglement_ratio, 0.0)
      pc = _as_float(program_communication, 0.0)
      par = _as_float(parallelism, 0.0)
      cd = _as_float(critical_depth, 0.0)
      comps = _as_int(num_connected_components, 0)
      nnlg = _as_int(num_nonlocal_gates, 0)

      # If num_qubits is known, keep sizes < num_qubits for meaningful decomposition.
      # Fallback to input size when metadata is missing.
      if n > 2:
          max_meaningful = n - 1
      elif n > 0:
          max_meaningful = n
      else:
          max_meaningful = max(2, in_size + 8)

      in_size = min(max_meaningful, max(2, in_size))

      # Circuit-family heuristics (must generalize; no per-benchmark branching).
      connected = (comps <= 2) if comps > 0 else True
      bv_like = (comps >= 4) and (er <= 0.30)
      ghz_like = connected and (er >= 0.85) and (par <= 0.20)

      dense_entangling = connected and (er >= 0.28) and (
          (n > 0 and nnlg >= n) or (nnlg >= 18 and pc >= 0.15)
      )

      high_risk = dense_entangling and (cd >= 0.9 or er >= 0.33 or pc >= 0.18)
      very_high_risk = high_risk and (
          (pc >= 0.25)
          or (n > 0 and nnlg >= 2 * n)
          or (er >= 0.55 and par <= 0.55)
      )

      # Risk-aware lower bound: prevent aggressive shrinking on dense, highly entangling circuits.
      floor_size = 3
      if high_risk:
          floor_size = max(floor_size, 5)
      if very_high_risk:
          floor_size = max(floor_size, 6)
      if ghz_like:
          floor_size = min(floor_size, 4)
      if bv_like:
          floor_size = 3

      # Risk-aware upper bound: allow backing off toward a near-no-op size for dense circuits.
      hi = in_size
      if (very_high_risk or high_risk) and (n > 0) and (not bv_like):
          # Bias toward keeping more qubits to avoid depth/CNOT blowups.
          target_hi = int(0.85 * float(n) + 0.5)
          hi = max(hi, min(max_meaningful, max(2, target_hi)))

      lo = min(hi, max(2, min(max_meaningful, floor_size)))
      if lo > hi:
          lo = hi

      # Cost probes with per-call caching to minimize pass invocations.
      _gv_cache = {}
      _wc_cache = {}

      def _compute_gv_cost(s):
          gv_pass = GVOptimalDecompositionPass(s)
          gv_cost_value = Value("i", 0)
          gv_pass.cost(q, gv_cost_value)
          return gv_cost_value.value

      def _compute_wc_cost(s):
          wc_pass = OptimalWireCuttingPass(s)
          wc_cost_value = Value("i", 0)
          wc_pass.cost(q, wc_cost_value)
          return wc_cost_value.value

      def get_costs(s):
          s = min(max_meaningful, max(2, _as_int(s, 2)))
          if s not in _gv_cache:
              _gv_cache[s] = _compute_gv_cost(s)
          if s not in _wc_cache:
              _wc_cache[s] = _compute_wc_cost(s)
          return _gv_cache[s], _wc_cache[s]

      gv_cost_trace = []
      wc_cost_trace = []

      def probe(s):
          gv, wc = get_costs(s)
          gv_cost_trace.append(gv)
          wc_cost_trace.append(wc)
          return gv, wc

      def feasible(gv, wc):
          return (gv <= b) or (wc <= b)

      # Ensure we have a feasible upper bound; if not, expand once (bounded).
      gv_hi, wc_hi = probe(hi)
      if (not feasible(gv_hi, wc_hi)) and (hi < max_meaningful):
          hi2 = min(max_meaningful, hi + 6)
          if hi2 != hi:
              hi = hi2
              gv_hi, wc_hi = probe(hi)

      if feasible(gv_hi, wc_hi):
          # Binary search for the smallest feasible size in [lo, hi].
          left, right = lo, hi
          while left < right:
              mid = (left + right) // 2
              gv_m, wc_m = probe(mid)
              if feasible(gv_m, wc_m):
                  right = mid
              else:
                  left = mid + 1
          min_feasible = left

          # Safety bump for dense circuits to reduce depth/CNOT regressions.
          bump = 0
          if high_risk:
              bump = 2
          if very_high_risk:
              bump = 4
          final_size = min(hi, min_feasible + bump)
      else:
          # No feasible size found in bounded range; fall back to the largest meaningful size.
          final_size = hi

      gv_cost, wc_cost = probe(final_size)

      # Method choice: use strict budget first; otherwise choose conservative preference.
      gv_ok = gv_cost <= b
      wc_ok = wc_cost <= b

      prefer_wc = bv_like or dense_entangling
      prefer_gv = ghz_like or ((not dense_entangling) and (er <= 0.22) and (comps >= 3))

      if gv_ok and wc_ok:
          if prefer_wc and not prefer_gv:
              method = "WC"
          elif prefer_gv and not prefer_wc:
              method = "GV"
          else:
              method = "GV" if gv_cost <= wc_cost else "WC"
      elif wc_ok:
          method = "WC"
      elif gv_ok:
          method = "GV"
      else:
          # Budget is only a heuristic; pick the lower-cost method at the chosen size.
          method = "GV" if gv_cost <= wc_cost else "WC"

      size_to_reach = int(final_size)
      # OE_END

      return size_to_reach, method

    POSSIBLE LEVERS TO EXPLORE:
      A) Decide to use WC or GV selectively instead of always using both.
      B) Explore size_to_reach efficiently instead of using two while loops iteratively.
      C) Explore early stopping rules for WC and GV.
      D) Skip certain size_to_reach values based on heuristics.

  evaluator_system_message: "You are a strict code reviewer. Do not add commentary."
  num_top_programs: 3
  num_diverse_programs: 2
  use_template_stochasticity: true

  # Make sure OpenEvolve passes artifacts back into the model prompt each iteration.
  include_artifacts: true
  max_artifact_bytes: 65536
  artifact_security_filter: true

database:
  db_path: null
  in_memory: true
  log_prompts: true

  population_size: 100
  archive_size: 20
  num_islands: 4

  migration_interval: 30
  migration_rate: 0.12

  elite_selection_ratio: 0.05
  exploration_ratio: 0.65
  exploitation_ratio: 0.30

  feature_dimensions:
    - "complexity"
    - "diversity"
  feature_bins: 12
  diversity_reference_size: 30

evaluator:
  timeout: 12000
  max_retries: 1
  cascade_evaluation: false
  parallel_evaluations: 1
  use_llm_feedback: false
  llm_feedback_weight: 0.0

evolution_trace:
  enabled: false
  format: "jsonl"
  include_code: false
  include_prompts: false
  output_path: null
  buffer_size: 10
  compress: false
