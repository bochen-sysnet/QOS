max_iterations: 100
checkpoint_interval: 10
log_level: "INFO"
log_dir: null
random_seed: 42
max_tasks_per_child: 1

# Rewrite mode: output full file each iteration (stable with OE markers)
diff_based_evolution: false
max_code_length: 30000

early_stopping_patience: null
convergence_threshold: 0.001
early_stopping_metric: "combined_score"

llm:
  api_base: "${OPENAI_API_BASE}"
  api_key: "${OPENAI_API_KEY}"
  # available gpt models: gpt-5.2, gpt-5.1, gpt-5, gpt-5-nano
  # available gemini models: gemini-2.5-flash-lite
  # available qwen models: Qwen/Qwen2.5-Coder-14B-Instruct-AWQ
  primary_model: "${OPENAI_MODEL}"
  temperature: 0.7
  top_p: 0.9
  max_tokens: 4096
  timeout: 450
  retries: 3
  retry_delay: 5

prompt:
  system_message: |
    You are optimizing ONLY the function evolved_cost_search(self, q, size_to_reach, budget)
    in qos/error_mitigator/evolution_target.py.

    OUTPUT FORMAT (CRITICAL):
    - Return the full file contents of qos/error_mitigator/evolution_target.py.
    - Output code only: no explanations, no markdown fences, no extra text.

    GENERALIZATION REQUIREMENT (CRITICAL):
    - The evaluator samples random (circuit_type, num_qubits) pairs each run.
    - Qubit counts are constrained to [12,24] and must exist in the benchmark set.
    - Your logic must generalize across circuit families (QAOA, BV, GHZ, VQE, QSVm, etc.) and sizes.
    - Do NOT branch on q.get_name(), bench strings, or any per-benchmark constants.

    FUNCTION CONTRACT (MUST FOLLOW EXACTLY):
    - Do NOT change the function signature.
      It MUST remain: evolved_cost_search(self, q, size_to_reach, budget)
    - It MUST return EXACTLY 2 values: (size_to_reach: int, method: str) where method is "GV" or "WC".
    - If you violate signature/return arity, evaluation will fail.

    CONTEXT:
    The input q is a Qernel. It contains metadata computed elsewhere, accessible via:
      input_meta = q.get_metadata()

    Useful fields may include:
      depth, num_qubits, num_clbits, num_nonlocal_gates, num_connected_components,
      number_instructions, num_measurements, num_cnot_gates,
      program_communication, liveness, parallelism, measurement,
      entanglement_ratio, critical_depth.

    COST HELPER APIS (from qos/error_mitigator/run.py):
      - compute_gv_cost(q, size_to_reach, timeout_sec=0)
      - compute_wc_cost(q, size_to_reach, timeout_sec=0)
      - Each call returns (cost: int, timed_out: bool).
      - timeout_sec is per-call; GV/WC can use different values.
      - timeout_sec=0 means no per-call timeout.
      - On timeout, cost is set high and timed_out=True.

    Inputs/Outputs:
      - Inputs:
          * q: the Qernel (quantum circuit container) whose metadata informs the decision.
          * size_to_reach: the current target circuit size for cutting/virtualization search.
          * budget: the cost threshold used to decide whether GV/WC is acceptable.
      - Outputs:
          * size_to_reach: the chosen target size to use for the cutting/virtualization of the target circuit.
          * method: "GV" or "WC", which determines which technique is applied at that size.
      - Cost logging and traces are handled outside this file (in qos/error_mitigator/run.py).

    IMPORTANT PRACTICAL CONSTRAINTS:
    - `budget` is only meaningful for your cost-search logic (i.e., your own GV/WC cost queries).
      Do not assume downstream will enforce budget.
    - If size_to_reach >= num_qubits, the decomposition can become a no-op.
      Use that ONLY as an explicit fallback when costs indicate everything else is too expensive.
      Prefer to clamp sizes into a meaningful range (e.g., [2, num_qubits-1]) for real action.

    EFFICIENCY / GENERALIZATION GUIDELINES (HIGH IMPACT):
    - Minimize gv/wc cost calls. Avoid long +/-1 stepping loops.
      Prefer a small number of probes + bounded search (e.g., check a few candidate sizes,
      or use a short binary/ternary-style search on a clamped interval).
    - Use cheap metadata heuristics first; only call compute_*_cost when needed.
    - Keep behavior monotone and stable: similar circuits should yield similar decisions.

    NOTE: "QOS" refers to the baseline implementation, and "QOSE" refers to the evolved program.

    METRICS:
      - qose_depth: average depth ratio (QOSE/QOS)
      - qose_cnot: average nonlocal gate ratio (QOSE/QOS)
      - qose_overhead: average circuit-count ratio (QOSE/QOS)
      - avg_run_time: average runtime ratio (QOSE/QOS)
      - combined_score (maximize): evaluator score used by evolution ranking.
        It uses global full-eval score during warmup, then surrogate prediction.
        Sampled circuits are selected by correlation with global score (from warmup history).
      - combined_score_sample_raw: sampled-circuit score from the base formula
        (kept for diagnostics; not used for ranking once surrogate is active).
      - combined_score_global / combined_score_pred_ml:
        optional diagnostic fields from evaluator when available.
    NOTE:
      - Depth/CNOT ratios are proxies for fidelity. The goal is to improve fidelity,
        reduce cost-search time, and avoid depth/CNOT regressions.

    We provide the execution outputs of the last program executed by the evaluator. 
    Use them to diagnose decisions. Details of the execution outputs are as follows:

    EXECUTION OUTPUTS PROVIDED BY EVALUATOR (summary):
      - qose_budget: budget used for all cases
      - qose_run_sec_avg: average runtime of evolved mitigator
      - qos_run_sec_avg: average runtime of baseline QOS
      - gv_cost_calls_total: total GV cost calls (evolved)
      - wc_cost_calls_total: total WC cost calls (evolved)
      - qos_gv_cost_calls_total: total GV cost calls (baseline)
      - qos_wc_cost_calls_total: total WC cost calls (baseline)
      - qos_depth_avg: average absolute depth of baseline circuits
      - qos_cnot_avg: average absolute nonlocal gate count of baseline circuits

    EXECUTION OUTPUTS PROVIDED BY EVALUATOR (per case):
      - input_features: static circuit features (depth, qubits, gates, etc.)
        num_connected_components, number_instructions, num_measurements, num_cnot_gates,
        program_communication, liveness, parallelism, measurement, entanglement_ratio, critical_depth
      - qose_input_size: initial target size before cost-search adjustments
      - qose_depth, qos_depth, qose_cnot, qos_cnot,
        qose_run_sec, qos_run_sec: paired QOSE vs baseline QOS metrics
      - qose_output_size: final target size chosen by the algorithm
      - qose_method: chosen method ("GV" or "WC")
      - qose_gv_cost_trace, qose_wc_cost_trace: cost estimates per probe step
      - qose_gv_time_trace, qose_wc_time_trace: time per probe step

    POSSIBLE LEVERS TO EXPLORE:
      A) Decide to use WC or GV selectively instead of always using both.
      B) Explore size_to_reach efficiently instead of using two while loops iteratively.
      C) Explore early stopping rules for WC and GV.
      D) Skip certain size_to_reach values based on heuristics.

    Example Evolution:
    ```
    from __future__ import annotations

    import math
    from typing import Callable, Dict, Tuple, Union, Any

    from qos.error_mitigator.run import compute_gv_cost, compute_wc_cost
    from qos.types.types import Qernel


    def evolved_cost_search(self, q: Qernel, size_to_reach: int, budget: int):
        metadata = q.get_metadata()
        depth = metadata.get("depth", 0)
        num_qubits = metadata.get("num_qubits", 0)
        num_clbits = metadata.get("num_clbits", 0)
        num_nonlocal_gates = metadata.get("num_nonlocal_gates", 0)
        num_connected_components = metadata.get("num_connected_components", 0)
        number_instructions = metadata.get("number_instructions", 0)
        num_measurements = metadata.get("num_measurements", 0)
        num_cnot_gates = metadata.get("num_cnot_gates", 0)
        program_communication = metadata.get("program_communication", 0.0)
        liveness = metadata.get("liveness", 0.0)
        parallelism = metadata.get("parallelism", 0.0)
        measurement = metadata.get("measurement", 0.0)
        entanglement_ratio = metadata.get("entanglement_ratio", 0.0)
        critical_depth = metadata.get("critical_depth", 0.0)

        # OE_BEGIN
        def _clamp_int(x: int, lo: int, hi: int) -> int:
            if x < lo:
                return lo
            if x > hi:
                return hi
            return x

        def _clamp_float(x: float, lo: float, hi: float) -> float:
            if x < lo:
                return lo
            if x > hi:
                return hi
            return x

        def _safe_cost_call(
            fn: Callable[..., Any], s: int, timeout_sec: float
        ) -> Tuple[float, bool]:
            """
            Returns (cost, timed_out). If the underlying helper doesn't support timeout
            or doesn't return a timed_out flag, we fall back gracefully.
            """
            try:
                out = fn(q, s, timeout_sec=timeout_sec)
            except TypeError:
                out = fn(q, s)

            # Common expected: (cost, timed_out)
            if isinstance(out, tuple) and len(out) >= 2:
                cost = float(out[0])
                timed_out = bool(out[1])
            else:
                cost = float(out)
                timed_out = False

            # Defensive normalization
            if math.isnan(cost) or cost < 0:
                cost = float("inf")
            if timed_out:
                cost = float("inf")
            return cost, timed_out

        # Normalize metadata for scale-free heuristics (generalize across qubit counts).
        n = int(num_qubits) if int(num_qubits) > 0 else max(2, int(size_to_reach) if int(size_to_reach) > 0 else 2)
        n = max(2, n)
        denom = float(max(1, n))

        nonlocal_density = float(num_nonlocal_gates) / denom
        instr_density = float(number_instructions) / denom
        depth_density = float(depth) / denom
        comp_penalty = math.log1p(max(0, int(num_connected_components) - 1))

        # A smooth "complexity" proxy (bounded), only used to set timeouts / probing.
        complexity = (
            0.35 * nonlocal_density
            + 0.25 * depth_density
            + 0.20 * instr_density
            + 0.10 * float(entanglement_ratio)
            + 0.10 * comp_penalty
        )
        complexity = _clamp_float(complexity, 0.0, 6.0)

        # Dynamic timeouts to avoid pathological cases (e.g., mid-size subgraphs) while
        # remaining permissive on easy instances. Keep bounded for stability.
        gv_timeout_sec = _clamp_float(0.15 + 0.65 * math.tanh(complexity / 2.0), 0.08, 0.90)
        wc_timeout_sec = _clamp_float(0.20 + 0.90 * math.tanh(complexity / 2.0), 0.10, 1.20)

        # Memoize cost evaluations to reduce repeated calls.
        # cache[s] = (gv_cost, wc_cost)
        cache: Dict[int, Tuple[float, float]] = {}

        def _eval_size(s: int) -> Tuple[float, str, float, float]:
            """
            Evaluate costs at size s and return:
            (best_cost, best_method, gv_cost, wc_cost)
            """
            s = max(2, int(s))
            if s in cache:
                gv_cost, wc_cost = cache[s]
            else:
                gv_cost, _gv_to = _safe_cost_call(compute_gv_cost, s, gv_timeout_sec)

                # Compute WC only when it can change the decision:
                # - GV infeasible (must try WC)
                # - or near boundary / structurally "split" circuits where WC can win
                #   (helps generalization; avoids overfitting to GV-only behavior).
                want_wc = False
                if gv_cost > float(budget):
                    want_wc = True
                else:
                    # Boundary or structure-triggered exploration
                    near_budget = gv_cost >= float(budget) - 1.0
                    split_like = (int(num_connected_components) > 1) or (float(program_communication) > 0.15)
                    low_ent = float(entanglement_ratio) < 0.25
                    want_wc = near_budget or split_like or low_ent

                if want_wc:
                    wc_cost, _wc_to = _safe_cost_call(compute_wc_cost, s, wc_timeout_sec)
                else:
                    wc_cost = float("inf")

                cache[s] = (gv_cost, wc_cost)

            best_cost = gv_cost
            best_method = "GV"
            if wc_cost < best_cost:
                best_cost = wc_cost
                best_method = "WC"

            return best_cost, best_method, gv_cost, wc_cost

        def _feasible(best_cost: float) -> bool:
            return best_cost <= float(budget)

        # Choose a robust starting point:
        # - Respect caller-provided size_to_reach
        # - Avoid starting too small on complex circuits (reduces oscillation/over-search)
        base_start = int(size_to_reach) if int(size_to_reach) > 0 else n
        # Complexity-adaptive floor (scale-free).
        # For harder circuits, start closer to n; for easier ones, allow smaller start.
        start_floor = int(round(n * (0.55 + 0.15 * math.tanh(complexity / 2.0))))
        start = max(base_start, start_floor)
        start = _clamp_int(start, 2, n)

        # Ensure we have a feasible upper point (may need to expand up to n).
        hi = start
        hi_best_cost, hi_best_method, _, _ = _eval_size(hi)
        if not _feasible(hi_best_cost):
            # Expand toward n with doubling steps (few evaluations).
            step = 1
            while hi < n and not _feasible(hi_best_cost):
                hi = min(n, hi + step)
                hi_best_cost, hi_best_method, _, _ = _eval_size(hi)
                step = min(step * 2, max(1, n))

            # If still infeasible at n, return the best effort at n (avoids infinite loops).
            if not _feasible(hi_best_cost):
                # Force WC evaluation at final size to avoid missing a feasible alternative.
                _, _, gv_c, wc_c = _eval_size(hi)
                if wc_c < gv_c:
                    return hi, "WC"
                return hi, "GV"

        # Step-down search (coarse-to-fine) for the smallest feasible size.
        candidate = hi
        step = max(1, (candidate - 2) // 2)
        while step >= 1:
            trial = candidate - step
            if trial < 2:
                step //= 2
                continue
            t_cost, _t_method, _, _ = _eval_size(trial)
            if _feasible(t_cost):
                candidate = trial
            else:
                step //= 2

        # Robustness margin: avoid picking a razor-thin boundary point that can fail
        # on nearby sizes/qubit-subsets. If tight, allow bumping size slightly.
        final_size = candidate
        final_cost, final_method, _, _ = _eval_size(final_size)
        slack = float(budget) - float(final_cost)

        if slack < 1.0:
            for bump in (1, 2):
                s2 = final_size + bump
                if s2 > n:
                    break
                c2, m2, _, _ = _eval_size(s2)
                if _feasible(c2) and (float(budget) - float(c2)) >= 1.0:
                    final_size, final_cost, final_method = s2, c2, m2
                    break

        # Tie-breaker for stability if WC was skipped (inf) but could be competitive:
        # if we are near budget, evaluate WC once at the final size.
        if float(budget) - float(final_cost) <= 1.0:
            gv_c, _ = _safe_cost_call(compute_gv_cost, final_size, gv_timeout_sec)
            wc_c, _ = _safe_cost_call(compute_wc_cost, final_size, wc_timeout_sec)
            if wc_c < gv_c and wc_c <= float(budget):
                final_method = "WC"
            else:
                final_method = "GV"

        # OE_END
        return final_size, final_method

    ```

  evaluator_system_message: "You are a strict code reviewer. Do not add commentary."
  num_top_programs: 3
  num_diverse_programs: 2
  use_template_stochasticity: true

  # Make sure OpenEvolve passes artifacts back into the model prompt each iteration.
  include_artifacts: true
  max_artifact_bytes: 65536
  artifact_security_filter: true

database:
  db_path: null
  in_memory: true
  log_prompts: true

  population_size: 100
  archive_size: 20
  num_islands: 4

  migration_interval: 30
  migration_rate: 0.12

  elite_selection_ratio: 0.05
  exploration_ratio: 0.65
  exploitation_ratio: 0.30

  feature_dimensions:
    - "complexity"
    - "diversity"
  feature_bins: 12
  diversity_reference_size: 30

evaluator:
  timeout: 12000
  max_retries: 1
  cascade_evaluation: false
  parallel_evaluations: 1
  use_llm_feedback: false
  llm_feedback_weight: 0.0

evolution_trace:
  enabled: false
  format: "jsonl"
  include_code: false
  include_prompts: false
  output_path: null
  buffer_size: 10
  compress: false
